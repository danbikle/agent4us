<code class='python'>
def compile(self, optimizer, metrics=[]):
    metrics += [mean_q]  # register default metrics

    # We never train the target model, hence we can set the optimizer and loss arbitrarily.
    self.target_model = clone_model(self.model, self.custom_model_objects)
    self.target_model.compile(optimizer='sgd', loss='mse')
    self.model.compile(optimizer='sgd', loss='mse')

    # Compile model.
    if self.target_model_update &lt; 1.:
        # We use the `AdditionalUpdatesOptimizer` to efficiently soft-update the target model.
        updates = get_soft_target_model_updates(self.target_model, self.model, self.target_model_update)
        optimizer = AdditionalUpdatesOptimizer(optimizer, updates)

    def clipped_masked_error(args):
        y_true, y_pred, mask = args
        loss = huber_loss(y_true, y_pred, self.delta_clip)
        loss *= mask  # apply element-wise mask
        return K.sum(loss, axis=-1)

    # Create trainable model. The problem is that we need to mask the output since we only
    # ever want to update the Q values for a certain action. The way we achieve this is by
    # using a custom Lambda layer that computes the loss. This gives us the necessary flexibility
    # to mask out certain parameters by passing in multiple inputs to the Lambda layer.
    y_pred = self.model.output
    y_true = Input(name='y_true', shape=(self.nb_actions,))
    mask = Input(name='mask', shape=(self.nb_actions,))
    loss_out = Lambda(clipped_masked_error, output_shape=(1,), name='loss')([y_pred, y_true, mask])
    ins = [self.model.input] if type(self.model.input) is not list else self.model.input
    trainable_model = Model(inputs=ins + [y_true, mask], outputs=[loss_out, y_pred])
    assert len(trainable_model.output_names) == 2
    combined_metrics = {trainable_model.output_names[1]: metrics}
    losses = [
        lambda y_true, y_pred: y_pred,  # loss is computed in Lambda layer
        lambda y_true, y_pred: K.zeros_like(y_pred),  # we only include this for the metrics
    ]
    trainable_model.compile(optimizer=optimizer, loss=losses, metrics=combined_metrics)
    self.trainable_model = trainable_model

    self.compiled = True
</code>
